{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongeun/ML/blob/tutorial/01_pytorch_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UFn7qZ8c9YV",
        "outputId": "5a8112bc-7da1-4b11-b360-7c0184ebcbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: pytorch version: 1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "print(\"INFO: pytorch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declaring data array in PyTorch"
      ],
      "metadata": {
        "id": "zlRzRhF-eR6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ```pytorch```, Tensors are the objects saving data.\n",
        "\n",
        "pytorch: 모든 오브젝트를 tensor로 모두 저장.\n",
        "integer, float 타입으로 저장."
      ],
      "metadata": {
        "id": "KFum3W5Jea1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declaring tensor of integers numbers\n",
        "tensor_int = torch.tensor([1,2,3])\n",
        "print(\"tensor_created\", tensor_int)\n",
        "print(\"type :\", type(tensor_int))\n",
        "print(\"shape:\", tensor_int.shape)\n",
        "print(\"dtype:\", tensor_int.dtype)\n",
        "print(\"device:\", tensor_int.device)\n",
        "print(\"---------------------------------------------\")\n",
        "# declaring tensor of floating numbers\n",
        "tensor_float = torch.tensor([1.,2.,3.])\n",
        "print(\"tensor_created\", tensor_float)\n",
        "print(\"type :\", type(tensor_float))\n",
        "print(\"shape:\", tensor_int.shape)\n",
        "print(\"dtype:\", tensor_float.dtype)\n",
        "print(\"device:\", tensor_int.device)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f10CqHVeeQ3c",
        "outputId": "e0fca7d4-6791-4c58-d42f-2ea1f266ec07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_created tensor([1, 2, 3])\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3])\n",
            "dtype: torch.int64\n",
            "device: cpu\n",
            "---------------------------------------------\n",
            "tensor_created tensor([1., 2., 3.])\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3])\n",
            "dtype: torch.float32\n",
            "device: cpu\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also convert numpy arrays to tensors.\n",
        "\n",
        "**Be careful that the default type for floating numbers are different**\n",
        "* pytorch: float32\n",
        "* numpy  : float64"
      ],
      "metadata": {
        "id": "lyn1T0DIekEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_int = np.array([[1],[2],[3]])\n",
        "print(\"ndarray_created\", arr_int)\n",
        "print(\"type :\", type(arr_int))\n",
        "print(\"shape:\", arr_int.shape)\n",
        "print(\"dtype:\", arr_int.dtype)\n",
        "print(\"---------------------------------------------\")\n",
        "arr_float = np.array([[1.],[2.],[3.]])\n",
        "print(\"ndarray_created\", arr_float)\n",
        "print(\"type :\", type(arr_float))\n",
        "print(\"shape:\", arr_float.shape)\n",
        "print(\"dtype:\", arr_float.dtype)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEZUXJzbehfr",
        "outputId": "0eb2f432-8b17-434f-b4fc-d2d214aa8195"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray_created [[1]\n",
            " [2]\n",
            " [3]]\n",
            "type : <class 'numpy.ndarray'>\n",
            "shape: (3, 1)\n",
            "dtype: int64\n",
            "---------------------------------------------\n",
            "ndarray_created [[1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "type : <class 'numpy.ndarray'>\n",
            "shape: (3, 1)\n",
            "dtype: float64\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 arr_float 를 tensor로 converting한다. \n",
        "**type을 지정할 때 중요**하다. \n",
        "\n",
        "**!주의 : gpu에 float64아니고 float32로 설정되어있다.**"
      ],
      "metadata": {
        "id": "nA9ZuiRJVaXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_float = torch.tensor(arr_float) # copy construct\n",
        "print(\"tensor_created\", tensor_float)\n",
        "print(\"type :\", type(tensor_float))\n",
        "print(\"shape:\", tensor_int.shape)\n",
        "print(\"dtype:\", tensor_float.dtype, \"<- torch inherits types of input data\")\n",
        "print(\"device:\", tensor_int.device)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJu6NCrieqE3",
        "outputId": "437d1a64-fbd4-4c6b-9b78-d5d7f5c83b49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_created tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]], dtype=torch.float64)\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3])\n",
            "dtype: torch.float64 <- torch inherits types of input data\n",
            "device: cpu\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This default type difference sometimes cause type error when you evaulate a neural network.\n",
        "Let us consider a following **multilayer perceptron (MLP) with two hidden layers and ReLU activations.**\n",
        "\n",
        "##\n",
        "Sequential모델을 이용. \n",
        "\n",
        "4개의 linear layer, activate function ReLu \\\\\n",
        "Linear 숫자 (n, m) : \\\\\n",
        "n = dimesion of input, 한개의 input 넣고 \\\\\n",
        "m = converted to dimension of output, 16개의 output 생성 \n",
        "2 hidden layer 넣기.\n",
        "\\\\\n",
        "\n",
        "numpy 는 cpu only (gpu off). \n",
        "\n",
        "다른 모델 import할때 gpu on 해야 함.\n"
      ],
      "metadata": {
        "id": "vjUoHJimfh2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 1),\n",
        ")"
      ],
      "metadata": {
        "id": "dhwKQ2bdfxYn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code will throw RuntimeError\n",
        "# please check your input types if this error pops up.\n",
        "model_mlp(tensor_float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "hWdbtcd3fUvy",
        "outputId": "5695e52c-9908-404c-aa45-e40a56be83e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7e67c1a91fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this code will throw RuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# please check your input types if this error pops up.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code will run without any problem.\n",
        "model_mlp(tensor_float.type(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PEddt4-fYhL",
        "outputId": "d8eaeae1-ffc7-44fb-86fb-cc58ad2ad9b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0544],\n",
              "        [-0.0542],\n",
              "        [-0.0683]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also \"Load external DATA\" and convert it to pytorch tensors for the data analysis.\n",
        "\n",
        "The following file contains **10000 random samples of the standard 2D gaussian.**"
      ],
      "metadata": {
        "id": "_CLKTQJbme6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download file...\n",
        "if not os.path.exists('data.std_normal_2d.npy'):\n",
        "    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19R7xHGTbWv9RoMW9dUtVDGVuzmTgF-Lt' -O data.std_normal_2d.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpvcJVG8mLn3",
        "outputId": "1be0f703-1c82-43e7-aa01-a1b0d284dbfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-06 13:36:51--  https://docs.google.com/uc?export=download&id=19R7xHGTbWv9RoMW9dUtVDGVuzmTgF-Lt\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.161.102, 142.251.161.100, 142.251.161.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.161.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-bs-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d009q0kg08d74m0fkqic43ajvis48d3q/1665063375000/10702479488373320068/*/19R7xHGTbWv9RoMW9dUtVDGVuzmTgF-Lt?e=download&uuid=7db2d4b4-28ae-4fca-8871-ce48bfa1cad0 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-06 13:36:51--  https://doc-00-bs-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d009q0kg08d74m0fkqic43ajvis48d3q/1665063375000/10702479488373320068/*/19R7xHGTbWv9RoMW9dUtVDGVuzmTgF-Lt?e=download&uuid=7db2d4b4-28ae-4fca-8871-ce48bfa1cad0\n",
            "Resolving doc-00-bs-docs.googleusercontent.com (doc-00-bs-docs.googleusercontent.com)... 74.125.129.132, 2607:f8b0:4001:c15::84\n",
            "Connecting to doc-00-bs-docs.googleusercontent.com (doc-00-bs-docs.googleusercontent.com)|74.125.129.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160128 (156K) [application/octet-stream]\n",
            "Saving to: ‘data.std_normal_2d.npy’\n",
            "\n",
            "data.std_normal_2d. 100%[===================>] 156.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-10-06 13:36:52 (158 MB/s) - ‘data.std_normal_2d.npy’ saved [160128/160128]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load external dataset\n",
        "arr_loaded    = np.load(\"data.std_normal_2d.npy\").astype(np.float32)\n",
        "tensor_loaded = torch.tensor(arr_loaded.astype(np.float32))\n",
        "print(\"tensor_created\", tensor_loaded)\n",
        "print(\"type :\", type(tensor_loaded))\n",
        "print(\"shape:\", tensor_loaded.shape)\n",
        "print(\"dtype:\", tensor_loaded.dtype)\n",
        "print(\"device:\", tensor_loaded.device)\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "# visualize the dataset\n",
        "arr_buffer = tensor_loaded.numpy()\n",
        "plt.hist2d(\n",
        "    arr_buffer[:,0],\n",
        "    arr_buffer[:,1],\n",
        "    bins=[20,20],\n",
        "    range=[[-2,2],[-2,2]],\n",
        "    #cmap=\"Greys\"\n",
        "    cmap=\"Reds\"\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.gca().set_aspect(1)\n",
        "plt.gca().set_xlabel(\"x\")\n",
        "plt.gca().set_ylabel(\"y\");"
      ],
      "metadata": {
        "id": "-x9YwWMtghFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "98005282-cf0b-44ba-c440-f9066dd905dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_created tensor([[ 0.0410, -0.5499],\n",
            "        [ 0.0914,  0.3845],\n",
            "        [-1.4588,  0.7957],\n",
            "        ...,\n",
            "        [ 0.1726,  1.0739],\n",
            "        [ 0.2596,  2.1876],\n",
            "        [-0.0886,  0.2547]])\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([10000, 2])\n",
            "dtype: torch.float32\n",
            "device: cpu\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic algebras in PyTorch"
      ],
      "metadata": {
        "id": "k0RmyQTHm1ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) pytorch supports the same algebraic operations available in NumPy."
      ],
      "metadata": {
        "id": "Lg0foQ8HnOK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor with zeros\n",
        "x = torch.zeros(size=(3,),dtype=torch.float32)\n",
        "print(x)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# tensor with ones\n",
        "y = torch.ones(size=(3,),dtype=torch.float32)\n",
        "print(y)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# elementary operations\n",
        "# 2*x + 3*y\n",
        "print(2*x + 3*y)\n",
        "print(\"---------------------------------\")\n",
        "# (2*y)^3\n",
        "print((2*y)**3)\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d02Bt_-BjzoL",
        "outputId": "f56a0a4f-551c-475d-a483-29af41b5b308"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n",
            "---------------------------------\n",
            "tensor([1., 1., 1.])\n",
            "---------------------------------\n",
            "tensor([3., 3., 3.])\n",
            "---------------------------------\n",
            "tensor([8., 8., 8.])\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) pytorch also has many built-in math functions."
      ],
      "metadata": {
        "id": "UgVpIMwInPfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(size=(3,),dtype=torch.float32)\n",
        "print(\"x      =\", x)\n",
        "print(\"log(x) =\", torch.log(x))\n",
        "print(\"exp(x) =\", torch.exp(x))\n",
        "print(\"sin(x) =\", torch.sin(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvtlg1Cdm238",
        "outputId": "9bfa2f60-503b-4edb-df03-a6b9ea677bac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x      = tensor([1., 1., 1.])\n",
            "log(x) = tensor([0., 0., 0.])\n",
            "exp(x) = tensor([2.7183, 2.7183, 2.7183])\n",
            "sin(x) = tensor([0.8415, 0.8415, 0.8415])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) pytorch tensors also follows the broadcasting rules for numpy arrays:"
      ],
      "metadata": {
        "id": "lt8mFRgunsjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# broadcastings....\n",
        "y = torch.ones(size=(4,3),dtype=torch.float32)\n",
        "print(y)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# 1 + y\n",
        "#   broadcasting (,) + (4,3) -> (4,3)\n",
        "print(1. + y)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# [1,2,3] + y\n",
        "#   broadcasting (3,) + (4,3) -> (4,3)\n",
        "print(torch.linspace(1.,3.,3) + y)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# [[1],[2],[3],[4]] + y\n",
        "#   broadcasting (4,1) + (4,3) -> (4,3)\n",
        "print(torch.linspace(1.,4.,4)[:,None] + y)\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0I2My4nHKD",
        "outputId": "688ba06c-6953-445b-e1f4-b48515f9ca7a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "---------------------------------\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "---------------------------------\n",
            "tensor([[2., 3., 4.],\n",
            "        [2., 3., 4.],\n",
            "        [2., 3., 4.],\n",
            "        [2., 3., 4.]])\n",
            "---------------------------------\n",
            "tensor([[2., 2., 2.],\n",
            "        [3., 3., 3.],\n",
            "        [4., 4., 4.],\n",
            "        [5., 5., 5.]])\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Derivatives"
      ],
      "metadata": {
        "id": "q0T8Cp5poJ9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two ways of calculating derivatives:\n",
        "- call backward function of given tensor : https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward\n",
        "- torch.autograd.grad() : https://pytorch.org/docs/stable/generated/torch.autograd.grad.html\n",
        "\n",
        "A quick summary of difference between those two can be found in: \n",
        "- https://pytorch.org/docs/stable/autograd.html\n",
        "- https://stackoverflow.com/questions/69148622/difference-between-autograd-grad-and-autograd-backward"
      ],
      "metadata": {
        "id": "8KEOmoZa4vvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor.backward():\n",
        "This method calculates gradients of given tensor with respect to all the graph leafs (the input tensors with requires_grad=True) and **accumulate** the gradient at tensor.grad field. \n",
        "\n",
        "This function is convenient for calculating derivatives during the network training."
      ],
      "metadata": {
        "id": "ezf2FnWB6Ka1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor(-1., requires_grad=True)\n",
        "print(\"x     =\", x)\n",
        "y=x**2\n",
        "print(\"y     =\", y)\n",
        "y.backward()\n",
        "print(\"dy/dx =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG_sHlHaoYaT",
        "outputId": "ddfd8ca1-7de7-4697-a549-d6f550bef17d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x     = tensor(-1., requires_grad=True)\n",
            "y     = tensor(1., grad_fn=<PowBackward0>)\n",
            "dy/dx = tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "! Be careful that backward() function is **accumulating** the gradients to the ```tensor.grad```, not saving the gradients.\n",
        "\n",
        "cf) I used ```retain_graph=True``` to keep the graph for backpropagation. Without this flag, the graph will be immediate released after computing gradinet, and you cannot backpropagate through the graph again. "
      ],
      "metadata": {
        "id": "6G_BY9Ki7zN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor(-1., requires_grad=True)\n",
        "print(\"x     =\", x)\n",
        "y=x**2\n",
        "print(\"y     =\", y)\n",
        "y.backward(retain_graph=True)   # used retain_graph=True to keep the graph for backpropagation. Without this flag, the graph will be immediate released after computing gradinetand you cannot backpropagate   \n",
        "print(\"dy/dx =\", x.grad)\n",
        "# calculating derivative of x^2?\n",
        "y.backward(retain_graph=True)\n",
        "print(\"dy/dx?=\", x.grad, \"<- this will not be -2, but (-2)+(-2)=-4\")\n",
        "# calculating derivative of x^2 after resetting the gradient\n",
        "x.grad = None\n",
        "y.backward()\n",
        "print(\"dy/dx =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY7BxjOp75OI",
        "outputId": "47f7a4c8-0e9f-4e20-97a9-9390c480defd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x     = tensor(-1., requires_grad=True)\n",
            "y     = tensor(1., grad_fn=<PowBackward0>)\n",
            "dy/dx = tensor(-2.)\n",
            "dy/dx?= tensor(-4.) <- this will not be -2, but (-2)+(-2)=-4\n",
            "dy/dx = tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.autograd.grad():"
      ],
      "metadata": {
        "id": "U0j6PpFy9_n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calculates gradient of given tensor with respect to the provided leaf tensor, i.e., ```torch.autograd.grad(y,x)``` will calculates dy/dx.\n",
        "This function is useful when you need to explicitly compute some derivatives and higher order derivatives."
      ],
      "metadata": {
        "id": "iKqY_8pQ-DlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor(-1., requires_grad=True)\n",
        "print(\"x      =\", x)\n",
        "y=x**2\n",
        "print(\"y      =\", y)\n",
        "dydx = torch.autograd.grad(y,x)[0] # this returns a tuple whose first componenet is the gradient.\n",
        "print(\"dy/dx  =\", dydx)\n",
        "print(\"x.grad =\", x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaxXiye1o2Nx",
        "outputId": "ae3eb3de-2b7e-4937-8c49-2e35a8be2d89"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x      = tensor(-1., requires_grad=True)\n",
            "y      = tensor(1., grad_fn=<PowBackward0>)\n",
            "dy/dx  = tensor(-2.)\n",
            "x.grad = None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating higher order derivatives are also straightforward with ```torch.autograd.grad()```, but you have to set flag ```create_graph=True``` to make the grad function create graphs for backpropagation."
      ],
      "metadata": {
        "id": "MfiFLYZj-pBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating 2nd order derivative of x^4\n",
        "x = torch.tensor(-1., requires_grad=True)\n",
        "print(\"x      =\", x)\n",
        "y=x**4\n",
        "print(\"y      =\", y)\n",
        "dy_dx = torch.autograd.grad(y, x, create_graph=True)[0] \n",
        "print(\"dy/dx  =\", dy_dx, \"<- you can see that grad_fn is also created\")\n",
        "ddy_dxdx = torch.autograd.grad(dy_dx, x)[0]\n",
        "print(\"d^2y/dx^2  =\", ddy_dxdx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6tn5Qvb--M-",
        "outputId": "b20c4a93-302e-487b-da51-19ca7d734521"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x      = tensor(-1., requires_grad=True)\n",
            "y      = tensor(1., grad_fn=<PowBackward0>)\n",
            "dy/dx  = tensor(-4., grad_fn=<MulBackward0>) <- you can see that grad_fn is also created\n",
            "d^2y/dx^2  = tensor(12.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient of non-scalar tensors"
      ],
      "metadata": {
        "id": "rpmXM0JC_p3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For calculating **gradients of non-scalar tensors**, we need **additional vector input** since the backpropagation algorithm or backward automatic differentition calculates the following vector-Jacobian product,\n",
        "\\begin{equation}\n",
        "(x_i)\\mathrm{.grad} =  v_i \\frac{dy_i}{d x_j}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "yVEUZaiIAJG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor([-1.,-2.], requires_grad=True)\n",
        "print(\"x     =\", x)\n",
        "y=x**2\n",
        "print(\"y     =\", y)\n",
        "y.backward()\n",
        "print(\"dy/dx =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Jx-y11_9_8RW",
        "outputId": "f2eb29b7-f24e-4941-98e0-7b368b8ab027"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x     = tensor([-1., -2.], requires_grad=True)\n",
            "y     = tensor([1., 4.], grad_fn=<PowBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-37ffe10fab23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y     =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dy/dx =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For component-wise differentiation, you may simply feed vectors whose components are all 1."
      ],
      "metadata": {
        "id": "_8nfKXHCAy3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor([-1.,-2.], requires_grad=True)\n",
        "print(\"x     =\", x)\n",
        "y=x**2\n",
        "print(\"y     =\", y)\n",
        "v = torch.ones_like(x)\n",
        "print(\"v     =\", seed)\n",
        "y.backward(gradient=seed)  # gradient is the input v_i in the above equation.\n",
        "print(\"dy/dx =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIJyUyjBnx3K",
        "outputId": "5d03f7ca-8f09-4983-e8a9-9937fef217bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x     = tensor([-1., -2.], requires_grad=True)\n",
            "y     = tensor([1., 4.], grad_fn=<PowBackward0>)\n",
            "v     = tensor([1., 1.])\n",
            "dy/dx = tensor([-2., -4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPUs for computing tensor operations"
      ],
      "metadata": {
        "id": "2XQfIQScCFU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we did all the calculation on CPU. \n",
        "\n",
        "In order to  use **GPU**, we have to declare tensors and models on GPU."
      ],
      "metadata": {
        "id": "hhWXjxNnCMl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scan available GPUs, \n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    print(\"# of GPUs: \", torch.cuda.device_count())\n",
        "    print(\"listing available GPUs...\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(\"device: cuda:{}\".format(i))\n",
        "        print(\"   GPU name: \",torch.cuda.get_device_name(i))\n",
        "        print(\"   cuda capability: major:{}, minor:{}\".format(*torch.cuda.get_device_capability(i)))\n",
        "        \n",
        "else:\n",
        "    print(\"GPU is NOT available\")"
      ],
      "metadata": {
        "id": "xw2XNQ9dCj6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783cd94f-6f78-4639-8840-2f90900bbe40"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "# of GPUs:  1\n",
            "listing available GPUs...\n",
            "device: cuda:0\n",
            "   GPU name:  Tesla T4\n",
            "   cuda capability: major:7, minor:5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the first GPU ```cuda:0```. For convenience, we will save the device object to device variable."
      ],
      "metadata": {
        "id": "RfJC3ErKEMQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"INFO: device will be used:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee2aQGagEKww",
        "outputId": "be746f9b-139a-4e02-a20e-a831a6d5ae65"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: device will be used: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a tensor on GPU, use device parameters when create a tensor."
      ],
      "metadata": {
        "id": "JMtb9onrFLpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declaring tensor of integers numbers\n",
        "tensor_int = torch.tensor([[1],[2],[3]], device=device)\n",
        "print(\"tensor_created\", tensor_int)\n",
        "print(\"type :\", type(tensor_int))\n",
        "print(\"shape:\", tensor_int.shape)\n",
        "print(\"dtype:\", tensor_int.dtype)\n",
        "print(\"device:\", tensor_int.device)\n",
        "print(\"---------------------------------------------\")\n",
        "# declaring tensor of floating numbers\n",
        "tensor_float = torch.tensor([[1.],[2.],[3.]], device=device)\n",
        "print(\"tensor_created\", tensor_float)\n",
        "print(\"type :\", type(tensor_float))\n",
        "print(\"shape:\", tensor_int.shape)\n",
        "print(\"dtype:\", tensor_float.dtype)\n",
        "print(\"device:\", tensor_int.device)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu678igzEudn",
        "outputId": "c0a440dc-5774-40ce-b735-c23c033f68a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_created tensor([[1],\n",
            "        [2],\n",
            "        [3]], device='cuda:0')\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3, 1])\n",
            "dtype: torch.int64\n",
            "device: cuda:0\n",
            "---------------------------------------------\n",
            "tensor_created tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]], device='cuda:0')\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3, 1])\n",
            "dtype: torch.float32\n",
            "device: cuda:0\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating derivative of x^2\n",
        "x = torch.tensor(-1., requires_grad=True, device=device)\n",
        "print(\"x     =\", x)\n",
        "y=x**2\n",
        "print(\"y     =\", y)\n",
        "y.backward()\n",
        "print(\"dy/dx =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7B8uiMcGUL4",
        "outputId": "64c69fea-06b5-45ee-ba61-d987766554ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x     = tensor(-1., device='cuda:0', requires_grad=True)\n",
            "y     = tensor(1., device='cuda:0', grad_fn=<PowBackward0>)\n",
            "dy/dx = tensor(-2., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also transfer tensors on CPU to GPU and vice versa."
      ],
      "metadata": {
        "id": "6ZQmNq8IFees"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU -> GPU\n",
        "tensor_float = torch.tensor([[1.],[2.],[3.]]).to(device)\n",
        "print(\"tensor_created\", tensor_float)\n",
        "print(\"type :\", type(tensor_float))\n",
        "print(\"shape:\", tensor_float.shape)\n",
        "print(\"dtype:\", tensor_float.dtype)\n",
        "print(\"device:\", tensor_float.device)\n",
        "print(\"---------------------------------------------\")\n",
        "# GPU -> CPU\n",
        "tensor_float = torch.tensor([[1.],[2.],[3.]],device=device).cpu()\n",
        "print(\"tensor_created\", tensor_float)\n",
        "print(\"type :\", type(tensor_float))\n",
        "print(\"shape:\", tensor_float.shape)\n",
        "print(\"dtype:\", tensor_float.dtype)\n",
        "print(\"device:\", tensor_float.device)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7J6iMPxFeFq",
        "outputId": "c8bdf750-5f0c-4abb-abf2-7644985cd884"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_created tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]], device='cuda:0')\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3, 1])\n",
            "dtype: torch.float32\n",
            "device: cuda:0\n",
            "---------------------------------------------\n",
            "tensor_created tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "type : <class 'torch.Tensor'>\n",
            "shape: torch.Size([3, 1])\n",
            "dtype: torch.float32\n",
            "device: cpu\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network model can be transferred, too."
      ],
      "metadata": {
        "id": "xUWnxbPnF2fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 1),\n",
        ").to(device)\n",
        "\n",
        "tensor_float = torch.tensor([[1.],[2.],[3.]], device=device)\n",
        "model_mlp(tensor_float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUMvendKGC4V",
        "outputId": "ee8eb338-953a-41ee-de92-35f026556351"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2691],\n",
              "        [0.2837],\n",
              "        [0.3218]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be careful that we cannot calculate algebraic operations on the tensors in different devices. "
      ],
      "metadata": {
        "id": "FalR-SVlGbZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_float = torch.tensor([[1.],[2.],[3.]]) # this tensor is on CPU!\n",
        "model_mlp(tensor_float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "sSQTd6WkGbF4",
        "outputId": "0328a6b6-0328-460a-d5ac-77ddf56b2186"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1e2da8672517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this tensor is on CPU!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to bring tensors on GPU on cpu and convert it to numpy array, here is a code snippet:"
      ],
      "metadata": {
        "id": "WKAH8ZFXG0en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_float = torch.tensor([[1.],[2.],[3.]], device=device)\n",
        "arr_float = tensor_float.cpu().numpy() # <- this one\n",
        "print(\"ndarray_created\", arr_float)\n",
        "print(\"type :\", type(arr_float))\n",
        "print(\"shape:\", arr_float.shape)\n",
        "print(\"dtype:\", arr_float.dtype)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgWl3iK4G72G",
        "outputId": "65ee4ef9-6787-4234-eecf-75aae813e475"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray_created [[1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "type : <class 'numpy.ndarray'>\n",
            "shape: (3, 1)\n",
            "dtype: float32\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if the tensor requires grad, we have to detach it from the graph first before the conversion."
      ],
      "metadata": {
        "id": "EP6kig-pHMcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_float = torch.tensor([[1.],[2.],[3.]], device=device, requires_grad=True)\n",
        "arr_float = tensor_float.detach().cpu().numpy() # <- try it without detach()\n",
        "print(\"ndarray_created\", arr_float)\n",
        "print(\"type :\", type(arr_float))\n",
        "print(\"shape:\", arr_float.shape)\n",
        "print(\"dtype:\", arr_float.dtype)\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0sfy9u3HXw8",
        "outputId": "4ed81c6d-965b-4c01-dac0-0d01b45b72d7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray_created [[1.]\n",
            " [2.]\n",
            " [3.]]\n",
            "type : <class 'numpy.ndarray'>\n",
            "shape: (3, 1)\n",
            "dtype: float32\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}